{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "homework_12-final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q7tITCr7cc2B"
      },
      "source": [
        "### DCGAN для генерации лиц \n",
        "\n",
        "Задача: обучить DCGAN для генерации лиц и изучить латентное пространство.\n",
        "\n",
        "\n",
        "Иллюстрация архитектуры ([источник](https://github.com/znxlwm/tensorflow-MNIST-GAN-DCGAN) иллюстрации).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8h5Crc7piLhS",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from IPython import display\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, BatchNormalization, LeakyReLU, Conv2DTranspose, Reshape, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "init = RandomNormal(mean=0.0, stddev=0.02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gtE8W61ib7O1",
        "colab": {}
      },
      "source": [
        "\n",
        "class DCGAN(tf.keras.Model):\n",
        "    def __init__(self, image_size, output_path, num_channels=1, z_dim=100,\n",
        "                 G_h_size=128, D_h_size=128):\n",
        "        \"\"\"\n",
        "        image_size -- размер стороны квадратной картинки\n",
        "        output_path -- путь для сохранения артефактов обучения. в корне -- картинки с разных итераций, \n",
        "        в папке model -- модель\n",
        "        num_channels -- количество каналов изображения\n",
        "        z_dim -- размерность латентного вектора\n",
        "        G_h_size -- минимальный размер фильтров в сверточных слоях генератора\n",
        "        D_h_size -- минимальный размер фильтров в сверточных слоях дискриминатора\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "        self.num_channels = num_channels\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.multiply = int(np.log2(self.image_size / 8)) # столько раз нужно применить апсемплинг или даунсемплинг\n",
        "                                                          # чтобы из (4,4) получить (image_size/2, image_size/2) и наоборот\n",
        "                                                \n",
        "        self.output_path =  Path(output_path)\n",
        "        (self.output_path / \"model\").mkdir(exist_ok=True)\n",
        "\n",
        "        self.G_h_size = G_h_size\n",
        "        self.D_h_size = D_h_size\n",
        "\n",
        "        self.generator = self._build_generator()\n",
        "        self.discriminator = self._build_discriminator()\n",
        "\n",
        "        self.optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5, beta_2=0.999)\n",
        "         \n",
        "        self.gen_loss_hist = []\n",
        "        self.disc_loss_hist = []\n",
        "        self._vis_h = 5\n",
        "        self._vis_w = 5\n",
        "        self._vis_noise = np.random.normal(0, 1, (self._vis_h* self._vis_w, self.z_dim)).astype(np.float32)\n",
        "        self.start_iteration = 0\n",
        "\n",
        "    def discriminator_loss(self, real_output, fake_output):\n",
        "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "        total_loss = real_loss + fake_loss\n",
        "        return total_loss\n",
        "\n",
        "    def generator_loss(self, fake_output):\n",
        "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    \n",
        "    def _conv_bn_leaky(self, kernel_size, channels, stride=1):\n",
        "        \"\"\"\n",
        "        Этот блок содержит Conv + BatchNorm + LeakyReLU\n",
        "\n",
        "        При указании stride=2 -- уменьшит размер в два раза.\n",
        "        \"\"\"\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(Conv2D(channels,\n",
        "                         kernel_size=kernel_size, padding=\"same\",\n",
        "                         use_bias=False, kernel_initializer=init,\n",
        "                         strides=(stride, stride))) # use_bias=False, т.к. BatchNorm и так вычтет среднее\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU())\n",
        "        return model\n",
        "        \n",
        "\n",
        "    def _build_generator(self):\n",
        "        \"\"\"\n",
        "        Генератор должен превращать вектор длины self.z_dim в \n",
        "        картинку image_size x image_size x num_channels\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        model = tf.keras.Sequential()\n",
        "        # для начала сделаем вектор -- трехмерным тензором с помощью Reshape\n",
        "        model.add(Reshape((1, 1, self.z_dim), input_shape=(self.z_dim,)))\n",
        "\n",
        "        # Превратим его в тензор размера (4, 4, self.G_h_size * 2**self.multiply)\n",
        "        model.add(Conv2DTranspose(self.G_h_size * 2**self.multiply,\n",
        "                                  kernel_size=4, use_bias=False, \n",
        "                                  kernel_initializer=init))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(LeakyReLU())\n",
        "\n",
        "        \n",
        "        for i in range(self.multiply):\n",
        "            model.add(UpSampling2D()) # увеличиваем картинку\n",
        "            model.add(self._conv_bn_leaky(4, self.G_h_size * 2**self.multiply // 2**(i+1))) # уменьшаем количество фильтров в два раза\n",
        "        \n",
        "        assert model.output_shape[1:] == (self.image_size // 2, self.image_size // 2, self.D_h_size), f\"{model.output_shape, self.D_h_size}\"\n",
        "        \n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(self.num_channels,\n",
        "                         kernel_size=4, strides=(1, 1),\n",
        "                         activation=\"tanh\", padding=\"same\", \n",
        "                         kernel_initializer=init))\n",
        "        return model\n",
        "\n",
        "    def _build_discriminator(self):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.InputLayer(\n",
        "            input_shape=((self.image_size, self.image_size, self.num_channels))))\n",
        "        model.add(self._conv_bn_leaky(kernel_size=4, \n",
        "                                      channels=self.D_h_size,\n",
        "                                      stride=2,\n",
        "                                      ))\n",
        "        \n",
        "        for i in range(self.multiply):\n",
        "            model.add(self._conv_bn_leaky(kernel_size=4, \n",
        "                                          channels=self.D_h_size * (2 ** (i+1)),\n",
        "                                          stride=2)) # количество фильтров увеличивается, размер уменьшается\n",
        "        assert model.output_shape[1:] == (4, 4, self.D_h_size * 2**self.multiply), f\"{model.output_shape}\"\n",
        "        model.add(Conv2D(1, kernel_size=4, kernel_initializer=init, use_bias=False)) # без активации !\n",
        "        model.add(Flatten())\n",
        "        return model\n",
        "    \n",
        "    @tf.function\n",
        "    def train_step(self, images):\n",
        "        noise = tf.random.normal([tf.cast(images.shape[0], tf.int32), self.z_dim])\n",
        "        \n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            generated_images = self.generator(noise, training=True)\n",
        "\n",
        "            real_output = self.discriminator(images, training=True)\n",
        "            fake_output = self.discriminator(generated_images, training=True)\n",
        "\n",
        "            gen_loss = self.generator_loss(fake_output)\n",
        "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
        "            \n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "        self.optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "        self.optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "        return gen_loss, disc_loss\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "        \"\"\"\n",
        "        Сохранение промежуточных картинок на диск\n",
        "        \"\"\"\n",
        "        gen_imgs = self.generator(self._vis_noise, training=False)\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "        fig, axs = plt.subplots(self._vis_h, self._vis_w, figsize=(6,6))\n",
        "        cnt = 0\n",
        "        for i in range(self._vis_h):\n",
        "            for j in range(self._vis_w):\n",
        "                if self.num_channels == 1:\n",
        "                    axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "                else:\n",
        "                    axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
        "                axs[i, j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(self.output_path / f\"{epoch}.png\")\n",
        "        plt.show()\n",
        "    \n",
        "    def train(self, dataset, num_iters=2000, show_every=25):\n",
        "        \"\"\"\n",
        "        Цикл обучения\n",
        "        \"\"\"\n",
        "        start = time.time()\n",
        "        iters = self.start_iteration\n",
        "        for image_batch in dataset:\n",
        "            print(\".\", end='')\n",
        "            gen_loss, disc_loss = self.train_step(image_batch)\n",
        "            \n",
        "            self.disc_loss_hist.append(disc_loss.numpy())\n",
        "            self.gen_loss_hist.append(gen_loss.numpy())    \n",
        "            \n",
        "            if iters % show_every == 0:\n",
        "                display.clear_output(wait=True)\n",
        "                plt.figure()\n",
        "                plt.plot(self.disc_loss_hist, label=\"Discriminator loss\")\n",
        "                plt.plot(self.gen_loss_hist, label=\"Generator loss\")\n",
        "                plt.legend(loc=\"best\")\n",
        "                plt.figure()\n",
        "                self.save_imgs(f\"{iters}\")\n",
        "                self.save_weights(str(self.output_path / \"model\" / \"dcgan_model\"), save_format='tf')\n",
        "                \n",
        "                print(f\"\\n{iters}/{num_iters}\")\n",
        "                print(f'Time elapsed from start {time.time() - start} sec')\n",
        "                \n",
        "            iters += 1\n",
        "            if iters > num_iters:\n",
        "                print(f'Finished. Time elapsed from start {time.time() - start} sec')\n",
        "                return\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kCjJjNuZq8Z2"
      },
      "source": [
        "### Загрузка датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QWk3u7BQ82Gu",
        "colab": {}
      },
      "source": [
        "# ! pip install gdown\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=0BxYys69jI14kYVM3aVhKS1VhRUk'\n",
        "output = '/tmp/UTKFace.tar.gz'\n",
        "gdown.download(url, output, quiet=False)\n",
        "! tar -xzf /tmp/UTKFace.tar.gz -C /tmp/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lswp2BjurIbu"
      },
      "source": [
        "### Создание генераторов данных\n",
        "\n",
        "*Интенсивности картинок должны быть нормализованы от -1 до 1.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yREA5Olfj-Il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "IMAGE_SIZE = 32\n",
        "# os.listdir(\"/tmp/UTKFace/\")\n",
        "\n",
        "image_dir = Path(\"/tmp/UTKFace/\")\n",
        "filenames = list(map(lambda x: x.name, image_dir.glob('*.jpg')))\n",
        "print(filenames[:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbd-R8kHsi-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# формируем датафрейм\n",
        "\n",
        "gender_mapping = {0: 'Male', 1: 'Female'}\n",
        "correct_filenames, gender_labels, = [], []\n",
        "\n",
        "for filename in filenames:\n",
        "    if len(filename.split('_')) != 4:\n",
        "        print(f\"Bad filename {filename}\")\n",
        "        continue\n",
        "\n",
        "    age, gender, race, _ = filename.split('_')\n",
        "    correct_filenames.append(filename)\n",
        "    gender_labels.append(gender)\n",
        "\n",
        "data = {\"img_name\": correct_filenames, \n",
        "        \"gender\": gender_labels}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0H5EKNtv9Cg0",
        "colab": {}
      },
      "source": [
        "# image_generator -- должен содержать необходимый генератор\n",
        "\n",
        "# нормализуем из 0..255 в -1..1\n",
        "def preprocess_input(image):\n",
        "    x = (image - 127.5) / 127.5 \n",
        "    return x\n",
        "\n",
        "image_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "image_generator = image_gen.flow_from_dataframe(df, \n",
        "                                                directory=str(image_dir), \n",
        "                                                x_col='img_name', \n",
        "                                                y_col='gender', \n",
        "                                                batch_size=BATCH_SIZE, \n",
        "                                                shuffle=True, \n",
        "                                                class_mode=None, \n",
        "                                                target_size=(IMAGE_SIZE, IMAGE_SIZE))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xaj8y1DNsEz0",
        "colab": {}
      },
      "source": [
        "sample = next(image_generator)\n",
        "assert sample.shape == (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3), f\"Размер батча должен быть: {(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3)}.  Получен {sample.shape}\"\n",
        "print(\"Shape test passed\")\n",
        "# если препроцессинг правильный, то картинка ниже имеет реалистичные цвета\n",
        "plt.imshow((sample[0] + 1.) / 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7UOg1sTNtoWO"
      },
      "source": [
        "### Обучение DCGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WmoGP2tDdw4y",
        "colab": {}
      },
      "source": [
        "# Для того, чтобы сохранять прогресс и веса модели, будем использовать google drive -- так модель не потеряется\n",
        "# и в случае отключения Colab - продолжить обучение.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jPNpsxKmxZoq",
        "colab": {}
      },
      "source": [
        "output = Path(\"/content/drive/My Drive/gan_utk_32\")\n",
        "output.mkdir(exist_ok=True)\n",
        "(output / \"model\").mkdir(exist_ok=True)\n",
        "\n",
        "gan = DCGAN(image_size=IMAGE_SIZE, num_channels=3, output_path=output, \n",
        "           z_dim=100, D_h_size=128, G_h_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OHEL_oEX22cQ",
        "colab": {}
      },
      "source": [
        "# если при запуске обучения вы видите \"WARNING:tensorflow:Entity <bound method DCGAN.train_step ...\", \n",
        "# раскомментируйте строчку ниже, установите пакет и рестартните runtime\n",
        "# это временный баг в tf из-за изменения версии gast\n",
        "# ! pip install 'gast==0.2.2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Vh_P313MW1z",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "images = list(output.glob(\"*.png\"))\n",
        "if images: # если папка не пуста, то продолжим обучение с последней итерации\n",
        "    iters = list(map(lambda x: int(x.name.split(\".\")[0]), images))\n",
        "    last_iter = sorted(iters)[-1]\n",
        "    gan.start_iteration = last_iter\n",
        "    print(f\"Resuming model from {last_iter} iteration\")\n",
        "     \n",
        "gan.train(image_generator, 10000, 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E83Q54FX7gJz"
      },
      "source": [
        "После того как модель обучена, можно посмотреть какие лица она научилась генерировать!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBlBJo3JU-rD",
        "colab": {}
      },
      "source": [
        "def generate_data(latent_vector, generator):\n",
        "    \"\"\"\n",
        "    Для того чтобы сгенерировать объект нам нужен генератор и латентный вектор\n",
        "    \"\"\"\n",
        "    gen_imgs = generator(latent_vector, training=False)\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    return gen_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4YkbdREtBoJ3",
        "colab": {}
      },
      "source": [
        "v1 = tf.random.normal([1, 100]) # случайный вектор\n",
        "print(\"Вектор: \", v1.numpy()[0, :10]) # распечатаем 10 первых элементов\n",
        "_ = plt.imshow(generate_data(v1, gan.generator)[0]) # сгенерированное лицо "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6hhpKylSBkcp"
      },
      "source": [
        "### Поиск вектора улыбки\n",
        "\n",
        "Найти “вектор улыбки” и доказать что он таковым является. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_1jbP1TFnGw",
        "colab": {}
      },
      "source": [
        "# вспомогательный код\n",
        "def generate_many(generator, n):\n",
        "    vis_noise = np.random.normal(0, 1, (n, 100)).astype(np.float32)\n",
        "    gen_imgs = generator(vis_noise, training=False)\n",
        "    show_many(gen_imgs, \"Generated images\")\n",
        "    return vis_noise\n",
        "\n",
        "def show_many(images, title=\"\"):\n",
        "    w = h = int(np.sqrt(len(images)))\n",
        "    images = (np.clip(images, -1, 1) + 1.) / 2. \n",
        "    \n",
        "    fig, axs = plt.subplots(w, h, figsize=(w, h))\n",
        "    if title != \"\":\n",
        "        fig.suptitle(title)\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            axs[i, j].imshow(images[cnt, :, :, :])\n",
        "            axs[i, j].set_title(f\"{cnt}\")\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    plt.subplots_adjust(wspace=.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3sBhd4laAxFP"
      },
      "source": [
        "### a) Интерполяция\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aDAlZHWY8_c0",
        "colab": {}
      },
      "source": [
        "def show_interpolation(v_1, v_2, generator, n=20):\n",
        "    \"\"\"\n",
        "    Превращает v_1 в v_2 за n шагов, изображая \n",
        "    картинки соответствующие промежуточным векторам\n",
        "\n",
        "    \"\"\"\n",
        "    fig, axs = plt.subplots(1, n, figsize=(n,1))\n",
        "    for i, alpha in enumerate(np.linspace(0, 1, n)):\n",
        "        curr_vec = v_1 * (1-alpha) + v_2 * alpha\n",
        "        image = generate_data(curr_vec, gan.generator)[0]\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3qo77raiHi_",
        "colab": {}
      },
      "source": [
        "v1 = tf.random.normal([1, 100])\n",
        "v2 = tf.random.normal([1, 100])\n",
        "\n",
        "show_interpolation(v1, v2, gan.generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gZORG_x7-1WJ"
      },
      "source": [
        "### b) Поиск вектора улыбки\n",
        "\n",
        "Функция generate_many для того чтобы получить 100 сгенерированных изображений и соответствующие им вектора.\n",
        "\n",
        "Лица пронумерованы и среди них есть лица\n",
        "с улыбкой. Выберем около 10 лиц с улыбкой и 10 без,\n",
        "запомним их номера. Затем посчитаем средний вектор\n",
        "лица без улыбки и средний вектор лица с улыбкой. Разница\n",
        "между ними и будет искомым вектором."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bO_1-qh29dD1",
        "colab": {}
      },
      "source": [
        "# поиск вектора улыбки\n",
        "\n",
        "# получаем 100 сгенерированных изображений и соответствующие им вектора\n",
        "gen_many = generate_many(gan.generator, 100)\n",
        "gen_many"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBDel5N2IqVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10 лиц с улыбкой \n",
        "smile_1 = #gen_many[i1]\n",
        "smile_2 = #gen_many[i2]\n",
        "smile_3 = #gen_many[i3]\n",
        "smile_4 = #gen_many[i4]\n",
        "smile_5 = #gen_many[i5]\n",
        "smile_6 = #gen_many[i6]\n",
        "smile_7 = #gen_many[i7]\n",
        "smile_8 = #gen_many[i8]\n",
        "smile_9 = #gen_many[i9]\n",
        "smile_10 = #gen_many[i10]\n",
        "\n",
        "# средний вектор лица с улыбкой \n",
        "smile_list = [smile_1, smile_2, smile_3, smile_4, smile_5, \n",
        "              smile_6, smile_7, smile_8, smile_9, smile_10]\n",
        "mean_vec_smile = sum(smile_list)/len(smile_list)\n",
        "\n",
        "# 10 лиц без улыбки \n",
        "not_smile_1 = #gen_many[i1]\n",
        "not_smile_2 = #gen_many[i2]\n",
        "not_smile_3 = #gen_many[i3]\n",
        "not_smile_4 = #gen_many[i4]\n",
        "not_smile_5 = #gen_many[15]\n",
        "not_smile_6 = #gen_many[i6]\n",
        "not_smile_7 = #gen_many[i7]\n",
        "not_smile_8 = #gen_many[i8]\n",
        "not_smile_9 = #gen_many[i9]\n",
        "not_smile_10 = #gen_many[i10]\n",
        "\n",
        "# средний вектор лица без улыбки\n",
        "not_smile_list = [not_smile_1, not_smile_2, not_smile_3, not_smile_4, not_smile_5, \n",
        "                  not_smile_6, not_smile_7, not_smile_8, not_smile_9, not_smile_10]\n",
        "mean_vec_not_smile = sum(not_smile_list)/len(not_smile_list)\n",
        "\n",
        "# искомый вектор улыбки\n",
        "vec_smile = mean_vec_smile - mean_vec_not_smile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CyomUOez887s",
        "colab": {}
      },
      "source": [
        "# нейтральный человек ------> с улыбкой\n",
        "not_smile_10 = tf.reshape(not_smile_10, [1, 100])\n",
        "vec_smile = tf.reshape(vec_smile, [1, 100])\n",
        "with_smile = not_smile_10 + vec_smile\n",
        "show_interpolation(not_smile_10, with_smile, gan.generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bm6UixR-9J89",
        "colab": {}
      },
      "source": [
        "# человек с улыбкой ------> нейтральный\n",
        "smile_8 = tf.reshape(smile_8, [1, 100])\n",
        "without_smile = smile_8 - vec_smile\n",
        "show_interpolation(smile_8, without_smile, gan.generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQDAckJX7gnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}